{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-20T14:31:50.136312900Z",
     "start_time": "2023-09-20T14:31:45.497856500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# from ckiptagger import data_utils, WS\n",
    "# ws = WS(\"./data\",disable_cuda=False) # ckiptagger æ¨¡å‹ \n",
    "\n",
    "import transformers\n",
    "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger, CkipNerChunker\n",
    "\n",
    "# from transformers import BertTokenizerFast, AutoModel\n",
    "# tokenizer = BertTokenizerFast.from_pretrained('ckiplab/albert-base-chinese-ner')\n",
    "# model = AutoModel.from_pretrained('ckiplab/albert-base-chinese-ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f15447c3097f0d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T14:32:00.603788900Z",
     "start_time": "2023-09-20T14:31:50.125831500Z"
    }
   },
   "outputs": [],
   "source": [
    "# è¼‰å…¥æ¨¡å‹ï¼Œdeviceåƒæ•¸ 0 = GPU, -1 = CPU\n",
    "ckip_ws = CkipWordSegmenter(model=\"bert-base\",device=-1)\n",
    "ckip_pos = CkipPosTagger(model=\"bert-base\",device=-1)\n",
    "ckip_ner = CkipNerChunker(model='bert-base',device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac229c0057be29cc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T14:32:00.603788900Z",
     "start_time": "2023-09-20T14:32:00.510566400Z"
    }
   },
   "outputs": [],
   "source": [
    "# text = ['é€™åƒ¹ä½çœŸçš„å¾ˆä¸è¡Œï¼Œå…¨éƒ¨åªæœ‰ç”œé»ä¸Šå¾—äº†æª¯é¢ï¼Œç‰¹åˆ¥æ˜¯å»æ‰€ï¼Œé›£ä»¥ç½®ä¿¡äº”æ˜Ÿç´šé£¯åº—çš„å»æ‰€é€£å…æ²»é¦¬æ¡¶éƒ½æ²’æœ‰ï¼ˆå¯èƒ½åœ¨æˆ¿é–“è£¡é¢ï¼‰ï¼Œæ•´é–“ç°ç°æš—æš—ï¼Œç‰†å£ç£ç£šé¡è‰²é‚„ä»¥ç‚ºæ˜¯ç™¼éœ‰ï¼ŒçœŸçš„å¾ˆå°ä¸èµ·ä¸€èµ·ä¾†èšé¤çš„åŒäº‹ï¼Œå®Œå…¨ä¸æ¨è–¦ã€‚']\n",
    "# \n",
    "# pos_text = ckip_ws(text)\n",
    "# print(pos_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b95d773f945ada",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## åŸå§‹è©•è«–ç•™è¨€æ–‡å­—æª”è™•ç†\n",
    "### ç›®æ¨™\n",
    "    - ä¾ç…§åˆ†é¡çˆ¬èŸ²ç²å–æ¯å®¶é¤å»³è©•è«–æ–‡å­—æª”è½‰æ›ç‚ºexcelé€è¡Œå„²å­˜æ¯å®¶é¤å»³è©•è«–\n",
    "        - excelæª”æ¡ˆæ¬„ä½è¡¨\n",
    "            - è©•è«–ç•™è¨€åŸå…§å®¹\n",
    "            - è©•è«–ç•™è¨€åŸºæœ¬è™•ç† (å»é™¤è¡¨æƒ…ç¬¦è™Ÿã€ç„¡æ„ç¾©å­—ç¬¦)\n",
    "            - æ–·è©è™•ç†å…§å®¹\n",
    "            - åœç”¨è©è™•ç†å…§å®¹\n",
    "\n",
    "### èª¿æ•´ç´€éŒ„\n",
    "    - ç•™è¨€ä¸­æœ‰äº›æ¶ˆè²»è€…çš„æ–‡ç« ä¸­æœ‰ç”¨åˆ°,æ‰€ä»¥åœ¨å¾ŒçºŒå°‡æ¯å‰‡è©•è«–ç•™è¨€ä»¥,ä½œç‚ºåˆ†éš”è­˜åˆ¥ä¸€å‰‡ä¸€å‰‡å­˜å…¥ä¸€è¡Œä¸€è¡Œdataframeä¸­æœƒé€ æˆæ¶ˆè²»è€…æ–‡ç« ä¸­ä½¿ç”¨çš„,å°‡æœ¬ä¾†æ˜¯åŒä¸€ç¯‡è©•è«–åˆ†éš”é–‹æˆå¥½å¹¾å‰‡é€ æˆè³‡æ–™éŒ¯èª¤å‚³å…¥\n",
    "        - æœ¬ä¾†æ˜¯å°‡è©•è«–.txtåšå®Œä¸€äº›åŸºç¤è™•è£¡å¾Œåœ¨è¼¸å‡ºç‚ºæ–°çš„è©•è«–.txtåˆ°æ–°çš„æª”æ¡ˆè·¯å¾‘ä¸­ï¼Œç¾åœ¨æ”¹æˆç›´æ¥æŠŠæœªè™•ç†çš„è©•è«–.txtç›´æ¥å…ˆä¾ç…§åˆ—è¡¨å½¢å¼é€ç­†å­˜å…¥dataframeä¸­\n",
    "    - ä¸å°‘è©•è«–ç•™è¨€ä¸­å‡ºç¾ ğŸ‘è¡¨æƒ…ç¬¦è™Ÿï¼Œé€™å€‹è¡¨æƒ…ç¬¦è™Ÿæ‡‰è©²æœ‰é«˜åº¦æ­£å‘æ„æ€ï¼Œä¸éæœƒåœ¨è³‡æ–™è™•ç†ä¸­èˆ‡å…¶ä»–è¡¨æƒ…ç¬¦è™Ÿè¢«å»é™¤ï¼Œæ‰€ä»¥åœ¨comment_text_basic_processingå‡½å¼ä¸­é å…ˆæ›¿æ›ç‚º 'è®š'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504af6cc420fdcd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# æª”æ¡ˆè®€å¯«path\n",
    "raw_restaurant_comments_folder = r\"\\å°ˆæ¡ˆå¯¦ä½œ\\åœ°å€é¤å»³è©•è«–åˆ†æ\\google_restaurant_comments_txt\\restaurant_comments_unprocessed\"\n",
    "revised_restaurant_comments_folder = r\"\\å°ˆæ¡ˆå¯¦ä½œ\\åœ°å€é¤å»³è©•è«–åˆ†æ\\google_restaurant_comments_txt\\restaurant_comments_processed\"\n",
    "\n",
    "\n",
    "def comment_text_basic_processing(data,col):\n",
    "    \"\"\"\n",
    "    ç•™è¨€ä¸­è¡¨æƒ…ç¬¦è™Ÿå­—ä¸²å»é™¤\n",
    "    ç‰¹å®šè¡¨æƒ…ç¬¦è™Ÿè½‰æ›ç‚ºå°æ‡‰æ„æ€ä¸­æ–‡è©å½™\n",
    "    :param data: \n",
    "    :param col: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    data[col] = data[col].str.replace('ğŸ‘','è®š')\n",
    "    \n",
    "    emoji_text = re.compile(\n",
    "        r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F700-\\U0001F77F'\n",
    "        r'\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF'\n",
    "        r'\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U0001FB00-\\U0001FBFF'\n",
    "        r'\\U0001FC00-\\U0001FCFF\\U0001FD00-\\U0001FDFF\\U0001FE00-\\U0001FEFF'\n",
    "        r'\\U0001FF00-\\U0001FFFF\\u2B05\\u2B06\\u2B07\\u2934\\u2935\\u25AA\\u25FE'\n",
    "        r'\\u2B05\\u2B06\\u2B07\\u2934\\u2935\\u25AA\\u25FE\\u2600-\\u26FF\\u2700-\\u27BF'\n",
    "        r'\\u2300-\\u23FF\\ufe0f]+',\n",
    "        flags=re.UNICODE)\n",
    "    data['è©•è«–ç•™è¨€åŸå…§å®¹è™•ç†'] = data[col].apply(lambda x:emoji_text.sub('',x))\n",
    "\n",
    "\n",
    "# ckiptagger ä¸­æ–‡æ–·è©è™•ç†\n",
    "# def segment_process(text):\n",
    "#     \"\"\"\n",
    "#     è©•è«–ç•™è¨€æ–·è©\n",
    "#     æ–·è©ä»¥ | åˆ†éš”\n",
    "#     :param text: \n",
    "#     :return: \n",
    "#     \"\"\"\n",
    "#     content_text = ws([text])\n",
    "#     return '|'.join(content_text[0])\n",
    "\n",
    "\n",
    "# ckip Transformers nlp bert model æ–·è©\n",
    "def segment_process_2(text):\n",
    "    \"\"\"\n",
    "    :param text: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    content_text = ckip_ws([text])\n",
    "    return '|'.join(content_text[0])\n",
    "\n",
    "\n",
    "def pos_process(text):\n",
    "    content_text = ckip_pos([text])\n",
    "    return  list(zip(text,content_text))\n",
    "\n",
    "\n",
    "# def ner_process(text):\n",
    "#     content_text = ckip_ner([text])\n",
    "#     return  content_text\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(raw_restaurant_comments_folder):\n",
    "    for dir in dirs:\n",
    "        print(\"è¦è™•ç†çš„é¤å»³é¡åˆ¥:\",dir)\n",
    "    for file_name in files:\n",
    "        print(\"è¦è™•ç†çš„è©•è«–æ–‡å­—æª”:\",os.path.join(root,file_name))\n",
    "    \n",
    "        if file_name.endswith(\".txt\"):\n",
    "            txt_file_path = os.path.join(root, file_name)\n",
    "            file_name = os.path.basename(txt_file_path)\n",
    "            # print(f\"æ­£åœ¨è™•ç†{file_name}è©•è«–æ–‡å­—æª”...\")\n",
    "        \n",
    "            # å‰µå»ºå°æ‡‰åŒåé¤å»³é¡åˆ¥è³‡æ–™å¤¾\n",
    "            sub_folder_name = os.path.basename(root)\n",
    "            revised_sub_folder_path = os.path.join(revised_restaurant_comments_folder,sub_folder_name)\n",
    "            os.makedirs(revised_sub_folder_path,exist_ok=True)\n",
    "            # print(f\"å·²å‰µå»º{revised_sub_folder_path}è³‡æ–™å¤¾\")\n",
    "\n",
    "            # æ‰“é–‹åŸå§‹è©•è«–æ–‡å­—æª”æ¡ˆè½‰æ›ç‚ºdataframe\n",
    "            try:\n",
    "                with open(txt_file_path, 'r',encoding='utf-8') as file:\n",
    "                    file_content = file.read()\n",
    "                comments_str_list = file_content.split(',') # data type is list\n",
    "                df_comments = pd.DataFrame(data=comments_str_list,columns=['è©•è«–ç•™è¨€åŸå…§å®¹'])\n",
    "                \n",
    "                # å°è©•è«–ç•™è¨€åŸå…§å®¹åšåŸºæœ¬è™•ç†å­˜æ”¾æ–¼æ–°æ¬„ä½\n",
    "                comment_text_basic_processing(df_comments,'è©•è«–ç•™è¨€åŸå…§å®¹')\n",
    "                df_comments['è©•è«–ç•™è¨€åŸå…§å®¹è™•ç†'] = df_comments['è©•è«–ç•™è¨€åŸå…§å®¹è™•ç†'].str.replace('[', '').str.replace(']', '').str.replace('\\\\n', '').str.replace(\"'\", '').str.replace('\\\\u200d','')\n",
    "                \n",
    "                # å°è©•è«–ç•™è¨€åŸå…§å®¹è™•ç†å¾Œé€²è¡Œæ–·è©è™•ç†\n",
    "                df_comments['è©•è«–ç•™è¨€å…§å®¹æ–·è©'] = df_comments['è©•è«–ç•™è¨€åŸå…§å®¹è™•ç†'].apply(segment_process_2)\n",
    "                \n",
    "                # å°è©•è«–ç•™è¨€æ–·è©å…§å®¹é€²è¡Œè©æ€§æ¨™è¨»\n",
    "                # df_comments['è©•è«–ç•™è¨€è©æ€§'] = df_comments['è©•è«–ç•™è¨€å…§å®¹æ–·è©'].apply(pos_process)\n",
    "                \n",
    "                # è½‰æ›ç‚ºdataframeå¾Œè¼¸å‡ºç‚ºexcelæª”æ¡ˆ\n",
    "                df_comments_file_name = os.path.splitext(file_name)[0] + '.xlsx'\n",
    "                df_comments_file_path = os.path.join(revised_sub_folder_path,df_comments_file_name)\n",
    "                df_comments.to_excel(df_comments_file_path,index=False)\n",
    "                print(f\"å·²å°‡{txt_file_path} --> excelæª”æ¡ˆï¼Œä¸”è½‰å­˜è‡³{revised_sub_folder_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"è½‰æ›æ–‡ä»¶{txt_file_path}ï¼Œå‡ºç¾éŒ¯èª¤:{str(e)}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# é€²è¡Œæ–·è©è™•ç†"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f2eec3d051d6ac0"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c2598b5badacea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# \n",
    "# # è¨­å®šä¸»è³‡æ–™å¤¾è·¯å¾‘\n",
    "# main_folder = r'\\å°ˆæ¡ˆå¯¦ä½œ\\åœ°å€é¤å»³è©•è«–åˆ†æ\\google_restaurant_comments_txt\\restaurant_comments_processed'\n",
    "# \n",
    "# # åˆå§‹åŒ–è®Šé‡ç”¨æ–¼å­˜å„²æ¯å€‹å­è³‡æ–™å¤¾çš„è³‡æ–™è¡Œæ•¸å’ŒExcelæ–‡ä»¶æ•¸é‡\n",
    "# total_rows = 0\n",
    "# total_files = 0\n",
    "# \n",
    "# # éæ­·ä¸»è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰å­è³‡æ–™å¤¾\n",
    "# for folder in os.listdir(main_folder):\n",
    "#     folder_path = os.path.join(main_folder, folder)\n",
    "#     \n",
    "#     # æª¢æŸ¥æ˜¯å¦ç‚ºè³‡æ–™å¤¾\n",
    "#     if os.path.isdir(folder_path):\n",
    "#         # åœ¨å­è³‡æ–™å¤¾ä¸­æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶\n",
    "#         excel_files = glob.glob(os.path.join(folder_path, '*.xlsx')) + glob.glob(os.path.join(folder_path, '*.xls'))\n",
    "#         \n",
    "#         # åˆå§‹åŒ–è®Šé‡ç”¨æ–¼å­˜å„²ç•¶å‰å­è³‡æ–™å¤¾çš„è³‡æ–™è¡Œæ•¸å’ŒExcelæ–‡ä»¶æ•¸é‡\n",
    "#         folder_rows = 0\n",
    "#         folder_files = len(excel_files)\n",
    "#         \n",
    "#         # éæ­·æ‰€æœ‰Excelæ–‡ä»¶\n",
    "#         for excel_file in excel_files:\n",
    "#             # è®€å–Excelæ–‡ä»¶\n",
    "#             df = pd.read_excel(excel_file)\n",
    "#             \n",
    "#             # ç²å–è³‡æ–™è¡Œæ•¸\n",
    "#             num_rows = df.shape[0]\n",
    "#             \n",
    "#             # æ‰“å°æ¯å€‹æª”æ¡ˆçš„è³‡æ–™è¡Œæ•¸\n",
    "#             print(f\"æª”æ¡ˆï¼š{excel_file}ï¼Œè³‡æ–™è¡Œæ•¸ï¼š{num_rows}\")\n",
    "#             \n",
    "#             # æ›´æ–°ç•¶å‰å­è³‡æ–™å¤¾çš„è³‡æ–™è¡Œæ•¸\n",
    "#             folder_rows += num_rows\n",
    "#         \n",
    "#         # æ›´æ–°ç¸½è³‡æ–™è¡Œæ•¸å’Œç¸½Excelæ–‡ä»¶æ•¸é‡\n",
    "#         total_rows += folder_rows\n",
    "#         total_files += folder_files\n",
    "#         \n",
    "#         # è¨ˆç®—ç•¶å‰å­è³‡æ–™å¤¾çš„å¹³å‡è³‡æ–™è¡Œæ•¸\n",
    "#         if folder_files > 0:\n",
    "#             average_rows = folder_rows / folder_files\n",
    "#             print(f\"å­è³‡æ–™å¤¾ï¼š{folder}ï¼Œå¹³å‡è³‡æ–™è¡Œæ•¸ï¼š{average_rows}\")\n",
    "#         else:\n",
    "#             print(f\"å­è³‡æ–™å¤¾ï¼š{folder}ï¼Œæ²’æœ‰Excelæ–‡ä»¶ã€‚\")\n",
    "# \n",
    "# # è¨ˆç®—æ‰€æœ‰å­è³‡æ–™å¤¾çš„å¹³å‡è³‡æ–™è¡Œæ•¸\n",
    "# if total_files > 0:\n",
    "#     overall_average = total_rows / total_files\n",
    "#     print(f\"æ‰€æœ‰å­è³‡æ–™å¤¾çš„å¹³å‡è³‡æ–™è¡Œæ•¸ï¼š{overall_average}\")\n",
    "# else:\n",
    "#     print(\"æ²’æœ‰Excelæ–‡ä»¶ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# from ckiptagger import data_utils, construct_dictionary, WS, POS\n",
    "# \n",
    "# # è¼‰å…¥æ¨¡å‹\n",
    "# ws = WS(\"./data\")\n",
    "# pos = POS(\"./data\")\n",
    "# \n",
    "# # è¨­å®šåœç”¨è©\n",
    "# stop_words = ['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æœ‰', 'æˆ‘', 'ä»–', 'å¥¹', 'ä½ ', 'å¦³']\n",
    "# \n",
    "# # è™•ç†æ–‡æœ¬\n",
    "# text = \"é€™æ˜¯ä¸€æ®µä¸­æ–‡æ–‡æœ¬ï¼Œæˆ‘å€‘è¦å°å®ƒé€²è¡Œåœç”¨è©è™•ç†ã€‚\"\n",
    "# word_sentence_list = ckip_ws([text])\n",
    "# pos_sentence_list = pos(word_sentence_list)\n",
    "# \n",
    "# # å»é™¤åœç”¨è©\n",
    "# for i, sentence in enumerate(word_sentence_list):\n",
    "#     for j, word in enumerate(sentence):\n",
    "#         if word in stop_words:\n",
    "#             word_sentence_list[i][j] = ''\n",
    "# print(word_sentence_list)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4b2c94b74bb8646"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
